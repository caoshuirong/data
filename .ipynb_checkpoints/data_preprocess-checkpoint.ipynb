{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024efc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff929c62",
   "metadata": {},
   "source": [
    "## 1.1 生成数据集 （修改window_len即可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv',header = None)\n",
    "\n",
    "# data = data.to_numpy()\n",
    "total_num = data.shape[0]\n",
    "total_len = data.shape[1]\n",
    "total_num\n",
    "total_len\n",
    "\n",
    "output_size = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_min 归一化\n",
    "def max_min(x,total_num):\n",
    "    min_val = x.values.min(axis=1)\n",
    "    max_val = x.values.max(axis=1)\n",
    "    values = (x.values-min_val.reshape(total_num,1))/(max_val - min_val).reshape(total_num,1)\n",
    "    return values,min_val,max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后生成测试数据时进行还原，然后与测试的label进行比较\n",
    "def max_min_reverse(x_numpy,min_val,max_val):\n",
    "    values = (x_numpy + min_val.reshape(total_num,1)) * (max_val - min_val).reshape(total_num,1)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max_min 归一化\n",
    "data,min_val,max_val = max_min(data,total_num)\n",
    "\n",
    "# data = max_min_reverse(data,min_val,max_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74182a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "\n",
    "window_len = 56\n",
    "\n",
    "train_series = data[:,0:total_len-output_size]\n",
    "train_size = train_series.shape[1]\n",
    "\n",
    "y_val_list = [data[i,total_len-output_size:] for i in range(total_num)]\n",
    "y_val_list[0].shape\n",
    "\n",
    "x_test_list = [data[i,total_len-window_len:] for i in range(total_num)]\n",
    "x_test_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo 滑动窗口截取\n",
    "# 每个样本的shape为(111,window_len) (111,window_len:window_len+56)\n",
    "\n",
    "\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_val_list = []\n",
    "for i in range(total_num):\n",
    "    for j in range(0,train_size - window_len-output_size,20):\n",
    "        x_train = train_series[i,j:j+window_len]\n",
    "        y_train = train_series[i,j+window_len:j+window_len+output_size]\n",
    "        x_train_list.append(x_train)\n",
    "        y_train_list.append(y_train)\n",
    "\n",
    "\n",
    "x_val_list = [train_series[i,train_size-output_size-window_len:] for i in range(total_num)]\n",
    "\n",
    "dataset ={\n",
    "    'x_train':x_train_list,\n",
    "    'y_train':y_train_list,\n",
    "    'x_val':x_val_list,\n",
    "    'y_val':y_val_list,\n",
    "    'x_test':x_test_list,\n",
    "    'max_val':max_val,\n",
    "    'min_val':min_val\n",
    "}\n",
    "\n",
    "# todo 问题在于 700多维的数据，LSTM记不住该如何划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dataset_%d.pkl'%window_len,'wb') as f:\n",
    "    pickle.dump(dataset,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7437eb3",
   "metadata": {},
   "source": [
    "## 1.2 封装数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658df7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as f\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.length = len(x_train)\n",
    "        self.data = [torch.Tensor(x_train[i]) for i in range(self.length)]\n",
    "        self.label = [torch.Tensor(y_train[i]) for i in range(self.length)]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index],self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c68752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装训练和验证集\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_val = dataset['x_val']\n",
    "y_val = dataset['y_val']\n",
    "min_val = dataset['min_val']\n",
    "max_val = dataset['max_val']\n",
    "    \n",
    "\n",
    "train_dataset = MyDataset(x_train,y_train)\n",
    "val_dataset = MyDataset(x_val,y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 32,shuffle = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = total_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装测试集\n",
    "x_test = dataset['x_test']\n",
    "y_test = pd.read_csv('test.csv',header = None)\n",
    "y_test = [y_test.iloc[i,:].to_numpy() for i in range(len(x_test))]\n",
    "test_dataset = MyDataset(x_test,y_test)\n",
    "test_loader = DataLoader(test_dataset,batch_size = total_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac2495",
   "metadata": {},
   "source": [
    "# 3.搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level = logging.INFO)\n",
    "handler = logging.FileHandler(\"log.txt\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40841f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class LossFunction(Enum):\n",
    "    MAE = 1\n",
    "    MSE = 2\n",
    "    SmoothL1 = 3\n",
    "\n",
    "class Mode(Enum):\n",
    "    Trian = 1\n",
    "    Valid = 2\n",
    "    Test = 3\n",
    "\n",
    "class Optim(Enum):\n",
    "    SGD = 1\n",
    "    Adam = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627bb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_weights(model):\n",
    "    for m in model.modules():\n",
    "#         if isinstance(m, nn.LSTM):\n",
    "#             [nn.init.orthogonal_(para) for name,para in m.name_parameters() if 'weight' in name]\n",
    "                \n",
    "        if isinstance(m,nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,rnn_inpt_size,rnn_hidden_size,dropout_rate=0.2):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.rnn_input_size = rnn_inpt_size\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,rnn_inpt_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.LSTM(rnn_inpt_size,rnn_hidden_size,batch_first=True)\n",
    "        self.apply(initial_weights)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        emb = self.linear(x) # batch size * seq_len\n",
    "        _,(h_n,_) = self.lstm(emb.reshape(x.shape[0],1,self.rnn_input_size))\n",
    "        \n",
    "        return h_n\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,ouput_size,rnn_inpt_size,rnn_hidden_size,dropout_rate=0.2):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.rnn_input_size = rnn_inpt_size\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "        self.linear = nn.Linear(rnn_hidden_size,ouput_size)\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "#         self.lstm = nn.LSTM(rnn_inpt_size,rnn_hidden_size,batch_first=True)\n",
    "#         self.apply(initial_weights)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        emb = self.linear(x.reshape(-1,self.rnn_hidden_size)) # batch size * seq_len\n",
    "        \n",
    "        return emb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,input_size,ouput_size,rnn_inpt_size,rnn_hidden_size,loss_type=LossFunction.MAE,dropout_rate=0.2):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.name = 'LSTM-based seq-to-seq'\n",
    "        self.loss_type = loss_type\n",
    "        self.encoder = Encoder(input_size,rnn_inpt_size,rnn_hidden_size,dropout_rate)\n",
    "        self.decoder = Decoder(ouput_size,rnn_hidden_size,rnn_hidden_size,dropout_rate)\n",
    "#         self.min = min_val\n",
    "#         self.max = max_val\n",
    "        if loss_type == LossFunction.MAE:\n",
    "            self.loss_fun = nn.L1Loss()\n",
    "        elif loss_type == LossFunction.MSE:\n",
    "            self.loss_fun = nn.MSELoss()\n",
    "        elif loss_type == LossFunction.SmoothL1:\n",
    "            self.loss_fun = nn.SmoothL1Loss()\n",
    "        else:\n",
    "            raise ValueError(\"please check loss_fun type!\")\n",
    "        \n",
    "    def forward(self,x,label=None):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "#         if mode == Mode.Test:\n",
    "#             out = max_min_reverse(out.cpu().detach().numpy(),self.min,self.max)\n",
    "        if label is not None:\n",
    "            loss = self.loss_fun(out,label)\n",
    "            out = (out,loss)\n",
    "            \n",
    "        return  out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4b94b",
   "metadata": {},
   "source": [
    "# 4.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    return 2.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self,model,train_loader,val_loader,test_loader,min_val,max_val,train_args):\n",
    "        super(Trainer,self).__init__()\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.lr = train_args['lr']\n",
    "        self.batch_size = train_args['batch_size']\n",
    "        self.optim_type = train_args['optim']\n",
    "        self.epochs = train_args['epochs']\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "        self.model.to(self.device)\n",
    "        self.min_loss = 1e8\n",
    "        self.best_model = None\n",
    "        self.normalize_min_val = min_val\n",
    "        self.mormalize_max_val = max_val\n",
    "        if self.optim_type == Optim.SGD:\n",
    "            self.optim = optim.SGD(self.model.parameters(),lr = self.lr)\n",
    "        elif self.optim_type == Optim.Adam:\n",
    "            self.optim = optim.Adam(self.model.parameters(),lr = self.lr)\n",
    "        else:\n",
    "            raise ValueError(\"Not a recognized optimizer\")\n",
    "    \n",
    "    def __train_one_peoch(self):\n",
    "        processbar = tqdm(range(self.train_loader.__len__()))\n",
    "        self.model.train()\n",
    "        train_loss = []\n",
    "        train_smape = []\n",
    "        for idx,(x_batch,y_batch) in enumerate(train_loader):\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            pred,loss = self.model(x_batch,y_batch)\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            train_loss.append(loss.item())\n",
    "            train_smape.append(SMAPE(pred.reshape(-1),y_batch))\n",
    "            processbar.update(1)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_smape = []\n",
    "            for idx,(x_batch,y_batch) in enumerate(val_loader):\n",
    "                x_batch = x_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                pred,loss = self.model(x_batch,y_batch)\n",
    "                val_loss.append(loss.item())\n",
    "                val_smape.append(self.SMAPE(pred.reshape(-1),y_batch))\n",
    "            epoch_train_loss = sum(train_loss) / len(train_loss)\n",
    "            epoch_train_smape = sum(train_smape) / len(train_smape)\n",
    "            epoch_val_loss = sum(val_loss) / len(val_loss)\n",
    "            epoch_val_smape = sum(val_smape) / len(val_smape)\n",
    "            \n",
    "        if epoch_val_loss < self.min_loss:\n",
    "            self.min_loss = epoch_val_loss\n",
    "            self.best_model = self.model\n",
    "\n",
    "        return epoch_train_loss,epoch_val_loss,epoch_train_smape,epoch_val_smape\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        epoch_train_smape_list = []\n",
    "        epoch_val_smape_list = []\n",
    "        for i in range(self.epochs):\n",
    "            train_loss,val_loss,epoch_train_smape,epoch_val_smape = self.__train_one_peoch()\n",
    "            info_str = \"train_loss:%.4f val_loss:%.4f train_smape:%.4f val_smape:%.4f\\n\" % (train_loss,val_loss,epoch_train_smape,epoch_val_smape)\n",
    "            print(infor_str)\n",
    "            train_loss_list.append(train_loss)\n",
    "            val_loss_list.append(val_loss)\n",
    "            epoch_train_smape_list.append(epoch_train_smape)\n",
    "            epoch_val_smape_list.append(epoch_val_smape)\n",
    "            if i % 21 == 0:\n",
    "                self.save_model(i)\n",
    "        title = 'len=%d + %s + %s + %s + '%(window_len,self.best_model.name,self.best_model.loss_type,self.optim_type.name)\n",
    "        info_str = title + 'train_loss:%.4f val_loss:%.4f train_smape:%.4f val_smape:%.4f\\n'%(train_loss,val_loss,epoch_train_smape,epoch_val_smape)\n",
    "        logging.info(info_str)\n",
    "        draw(train_loss_list,val_loss_list,'epochs','loss',['train_loss','val_loss'],title)\n",
    "        draw(epoch_train_smape_list,epoch_val_smape_list,'epochs','smape',['train_smape','val_smape'],title)\n",
    "        \n",
    "        \n",
    "    def draw(self,y1,y2,xlabel,ylabel,lengend,title):\n",
    "        x = [i for i in range(len(y1))]\n",
    "        plt.plot(x,y1,x,y2)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.lengend(lengend)\n",
    "        plt.title(title)\n",
    "        plt.savefig(\"%s.png\"%title)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def eval(self,test_loader):\n",
    "        self.model.eval()\n",
    "        test_loss = []\n",
    "        with torch.no_grad():\n",
    "            # batch_size == total_num\n",
    "            for idx,(x_batch,y_batch) in enumerate(test_loader):\n",
    "                x_batch = x_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                pred,loss = self.model(x_batch,y_label)\n",
    "                test_loss.append(loss.item())\n",
    "            test_loss = sum(test_loss) / len(test_loss)\n",
    "            smape_val = self.SMAPE(pred.reshape(-1),y_batch,Mode.Test)\n",
    "            \n",
    "        return test_loss,smape_val\n",
    "\n",
    "    \n",
    "    def SMAPE(self,pred,y_batch,mode=Mode.Trian):\n",
    "        pred = max_min_reverse(pred.cpu().numpy(),self.normalize_min_val,self.nmormalize_max_val)\n",
    "        if mode == Mode.Test:\n",
    "            y_batch = y_batch.cpu().numpy().reshape(-1)\n",
    "        else:\n",
    "            y_batch = max_min_reverse(y_batch.cpu().numpy(),self.normalize_min_val,self.nmormalize_max_val)\n",
    "        smape_val= smape(pred.reshape(-1),y_batch)\n",
    "        return smape_val\n",
    "        \n",
    "    def save_model(self,epoch=None):\n",
    "        if epoch is not None:\n",
    "            torch.save(self.best_model,'./checkpoint/len=%d + %s + %s + %s + checkpoint: %d.pt'\n",
    "                       %(window_len,self.best_model.name,self.best_model.loss_type,self.optim_type.name,epoch))\n",
    "        torch.save(self.best_model,'./checkpoint/len=%d + %s + %s + %s + test.pt'\n",
    "                       %(window_len,self.best_model.name,self.best_model.loss_type,self.optim_type.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"input_size\": window_len+output_size,\n",
    "    'output_size':output_size,\n",
    "    \"rnn_inpt_size\" : 128,\n",
    "    \"rnn_hidden_size\": 256,\n",
    "    \"loss_type\":LossFunction.MAE,\n",
    "    'dropout_rate':0.2\n",
    "}\n",
    "\n",
    "train_args = {\n",
    "    'lr' : 3e-4,\n",
    "    'batch_size' : 32,\n",
    "    'dropout_rate' : 0.2,\n",
    "    'optim' : Optim.SGD,\n",
    "    'epochs' : 300,\n",
    "}\n",
    "\n",
    "model = Seq2Seq(input_size=model_args[\"input_size\"],ouput_size=model_args['output_size'],\n",
    "                rnn_inpt_size=model_args['rnn_inpt_size'],rnn_hidden_size=model_args['rnn_hidden_size'],\n",
    "                loss_type=model_args['loss_type'],dropout_rate=model_args['dropout_rate'])\n",
    "\n",
    "trainer = Trainer(model,train_loader,val_loader,test_loader,min_val,max_val,train_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496a8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
